{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model():\n",
    "    key, endpoint = os.getenv('COGNITIVE_SERVICES_API_KEY'), os.getenv('COGNITIVE_SERVICES_ENDPOINT')\n",
    "    model_id = os.getenv('COGNITIVE_SERVICES_MODEL_ID')\n",
    "    #test_file = \"./2311.07198.pdf\"\n",
    "\n",
    "    document_analysis_client = DocumentAnalysisClient(\n",
    "        endpoint=endpoint, credential=AzureKeyCredential(key)\n",
    "    )\n",
    "\n",
    "    # from azure storage blob\n",
    "    # file_url = \"https://lgengstorage.blob.core.windows.net/training/2311.07198.pdf\"\n",
    "    # poller = document_analysis_client.begin_analyze_document_from_url(model_id=model_id, document_url=file_url)\n",
    "    #Message: Invalid request.\n",
    "    # Inner error: {\n",
    "    #     \"code\": \"InvalidManagedIdentity\",\n",
    "    #     \"message\": \"The managed identity configuration is invalid: Managed identity is not enabled for the current resource.\"\n",
    "    # }\n",
    "\n",
    "    # from local file\n",
    "    file_path = \"./2311.07198.pdf\"\n",
    "    with open(file_path, \"rb\") as f: \n",
    "        poller = document_analysis_client.begin_analyze_document(model_id=model_id, document=f)\n",
    "\n",
    "    #poller = document_analysis_client.begin_analyze_document_from_url(model_id, test_file)\n",
    "    result = poller.result()\n",
    "\n",
    "    for idx, document in enumerate(result.documents):\n",
    "        print(\"--------Analyzing document #{}--------\".format(idx + 1))\n",
    "        print(\"Document has type {}\".format(document.doc_type))\n",
    "        print(\"Document has confidence {}\".format(document.confidence))\n",
    "        print(\"Document was analyzed by model with ID {}\".format(result.model_id))\n",
    "        for name, field in document.fields.items():\n",
    "            field_value = field.value if field.value else field.content\n",
    "            print(\"......\"+name+\"......\")\n",
    "            print(\"......found field of type '{}' with value '{}' and with confidence {}\".format(field.value_type, field_value, field.confidence))\n",
    "\n",
    "\n",
    "    # iterate over tables, lines, and selection marks on each page\n",
    "    # for page in result.pages:\n",
    "    #     print(\"\\nLines found on page {}\".format(page.page_number))\n",
    "    #     for line in page.lines:\n",
    "    #         print(\"...Line '{}'\".format(line.content.encode('utf-8')))\n",
    "    #     for word in page.words:\n",
    "    #         print(\n",
    "    #             \"...Word '{}' has a confidence of {}\".format(\n",
    "    #                 word.content.encode('utf-8'), word.confidence\n",
    "    #             )\n",
    "    #         )\n",
    "    #     for selection_mark in page.selection_marks:\n",
    "    #         print(\n",
    "    #             \"...Selection mark is '{}' and has a confidence of {}\".format(\n",
    "    #                 selection_mark.state, selection_mark.confidence\n",
    "    #             )\n",
    "    #         )\n",
    "\n",
    "    # for i, table in enumerate(result.tables):\n",
    "    #     print(\"\\nTable {} can be found on page:\".format(i + 1))\n",
    "    #     for region in table.bounding_regions:\n",
    "    #         print(\"...{}\".format(i + 1, region.page_number))\n",
    "    #     for cell in table.cells:\n",
    "    #         print(\n",
    "    #             \"...Cell[{}][{}] has content '{}'\".format(\n",
    "    #                 cell.row_index, cell.column_index, cell.content.encode('utf-8')\n",
    "    #             )\n",
    "    #         )\n",
    "    print(\"-----------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Analyzing document #1--------\n",
      "Document has type 20231114_2\n",
      "Document has confidence 0.997\n",
      "Document was analyzed by model with ID 20231114_2\n",
      "......papername......\n",
      "......found field of type 'string' with value 'MonoDiffusion: Self-Supervised Monocular Depth Estimation Using Diffusion Model' and with confidence 0.552\n",
      "......authorlist......\n",
      "......found field of type 'string' with value 'Shuwei Shao, Zhongcai Pei, Weihai Chen*, Dingchi Sun, Peter C.Y.Chen and Zhengguo Li, Fellow, IEEE' and with confidence 0.623\n",
      "......abstract......\n",
      "......found field of type 'string' with value 'Abstract-Over the past few years, self-supervised monocular depth estimation that does not depend on ground-truth during the training phase has received widespread attention. Most efforts focus on designing different types of network architectures and loss functions or handling edge cases, e.g., occlusion and dynamic objects. In this work, we introduce a novel self-supervised depth estimation framework, dubbed MonoDiffusion, by formulating it as an iterative denoising process. Because the depth ground-truth is unavailable in the training phase, we develop a pseudo ground- truth diffusion process to assist the diffusion in MonoDiffusion. The pseudo ground-truth diffusion gradually adds noise to the depth map generated by a pre-trained teacher model. Moreover, the teacher model allows applying a distillation loss to guide the denoised depth. Further, we develop a masked visual condition mechanism to enhance the denoising ability of model. Extensive experiments are conducted on the KITTI and Make3D datasets and the proposed MonoDiffusion outperforms prior state-of-the- art competitors. The source code will be available at https:// github.com/ShuweiShao/MonoDiffusion.' and with confidence 0.087\n",
      "......pagenumber......\n",
      "......found field of type 'string' with value '1' and with confidence 0.708\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__': \n",
    "    test_model()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
